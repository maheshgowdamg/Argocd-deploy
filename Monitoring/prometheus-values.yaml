  values:
    grafana:
      admin:
        existingSecret: grafana-admin
        userKey: admin-user
        passwordKey: admin-password
      datasources:
        datasources.yaml:
          apiVersion: 1
          datasources:
            - name: Prometheus
              type: prometheus
              url: http://prometheus-kube-prometheus-prometheus:9090
              access: proxy
              isDefault: false
      persistence:
        enabled: true
        size: 1Gi
        accessModes:
          - ReadWriteOnce
      ingress:
        enabled: true
        ingressClassName: nginx
        path: /
        pathType: Prefix
        hosts:
          - mykaremonitor-qa.hatiintl.com
    alertmanager:
      alertmanagerSpec:
        logFormat: json
        logLevel: warn
      config:
        receivers:
          - name: "null"
          - name: "robusta"
            webhook_configs:
              - url: "http://robusta-runner.monitoring.svc.cluster.local/api/alerts"
                send_resolved: true
        route:
          receiver: "robusta"
          routes:
            - receiver: "null"
              match:
                alertname: KubeHpaMaxedOut
            - receiver: "null"
              match:
                alertname: KubeMemoryOvercommit
            - receiver: "null"
              match:
                alertname: KubeCPUOvercommit
            - receiver: "robusta"
              continue: true
    defaultRules:
      rules:
        kubeControllerManager: false
        kubeProxy: false
        kubeSchedulerAlerting: false
    additionalPrometheusRulesMap:
      rule-name:
        groups:
          - name: PodMemoryHighUsage
            rules:
              - alert: PodMemoryHighUsage
                expr: (sum by (cluster, container, pod, namespace) (node_namespace_pod_container:container_memory_working_set_bytes{namespace="qa"})) / (sum by (cluster, container, pod, namespace) (cluster:namespace:pod_memory:active:kube_pod_container_resource_limits{namespace="qa"})) > 0.9
                for: 10m
                labels:
                  severity: warning
                annotations:
                  summary: "High Memory Usage Detected!"
                  description: "ðŸš¨ Cluster *{{ $labels.cluster }}* - Pod *{{ $labels.namespace }}/{{ $labels.pod }}* (Container: *{{ $labels.container }}*) is using more than 90% of its memory limit."
    prometheus:
      prometheusSpec:
        logFormat: json
        logLevel: warn
        retention: 7d
        retentionSize: 7GB
        storageSpec:
          volumeClaimTemplate:
            spec:
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 8Gi
        externalLabels:
          cluster: medvista-k8s-v2-qa-sit
        additionalScrapeConfigs:
          - job_name: "postgresql-monitoring"
            scrape_timeout: 1m0s
            scrape_interval: 1m0s
            metrics_path: /metrics
            params:
              module: [http_2xx]
            static_configs:
              - targets:
                  - postgresql-metrics.qa:9187
            relabel_configs:
              - source_labels: [__address__]
                target_label: __param_target
              - source_labels: [__param_target]
                target_label: instance
              - target_label: __address__
                replacement: postgresql-metrics.qa:9187
          - job_name: "mongo-monitoring"
            scrape_timeout: 1m0s
            scrape_interval: 1m0s
            metrics_path: /metrics
            params:
              module: [http_2xx]
            static_configs:
              - targets:
                  - mongo-mongodb-metrics.qa:9216
            relabel_configs:
              - source_labels: [__address__]
                target_label: __param_target
              - source_labels: [__param_target]
                target_label: instance
              - target_label: __address__
                replacement: mongo-mongodb-metrics.qa:9216

